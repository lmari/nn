{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un semplice esempio di uso dell'API di ChatGPT in modalità _streaming_/sequenziale \n",
    "Luca Mari, aprile 2023\n",
    "\n",
    "(ispirato da https://til.simonwillison.net/gpt3/python-chatgpt-streaming-api)\n",
    "\n",
    "Dopo aver installato il modulo `openai` e aver definito, in `.bashrc`, le due variabili d'ambiente `OPENAI_ORGANIZATION` e `OPENAI_API_KEY`, i cui valori sono presi dal sito di OpenAI..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.organization = os.getenv('OPENAI_ORGANIZATION')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... si può indicare un prompt, e quindi inviare la richiesta, qui formattata in accordo al wrapper Python dell'API, in modalità _streaming_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seno: Ciao Coseno, come stai oggi?\n",
      "\n",
      "Coseno: Ciao Seno, sto bene grazie. E tu?\n",
      "\n",
      "Seno: Anch'io sto bene. Sai, mi piace come lavoriamo insieme per calcolare le funzioni trigonometriche.\n",
      "\n",
      "Coseno: Sì, è vero. Senza di me, tu non potresti fare molto. E senza di te, io non potrei fare nulla.\n",
      "\n",
      "Seno: Esatto. Siamo come un team perfetto.\n",
      "\n",
      "Coseno: È vero. Ma a volte mi sento un po' in ombra rispetto a te. Tutti parlano sempre di te quando si tratta di funzioni trigonometriche.\n",
      "\n",
      "Seno: Non preoccuparti, Coseno. Senza di te, le funzioni trigonometriche non sarebbero complete. Sei altrettanto importante quanto me.\n",
      "\n",
      "Coseno: Grazie, Seno. Apprezzo molto le tue parole.\n",
      "\n",
      "Seno: Dobbiamo continuare a lavorare insieme per risolvere i problemi matematici. Siamo una squadra imbattibile.\n",
      "\n",
      "Coseno: Sì, hai ragione. Andiamo avanti, Seno."
     ]
    }
   ],
   "source": [
    "prompt = 'Inventa un dialogo tra seno e coseno.' # questo è il prompt\n",
    "\n",
    "messages = [{'role':'user', 'content':prompt}]\n",
    "\n",
    "for chunk in openai.ChatCompletion.create( # genera la risposta\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=messages,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    "    stream=True\n",
    "):\n",
    "    content = chunk[\"choices\"][0].get(\"delta\", {}).get(\"content\")\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
